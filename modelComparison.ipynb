{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7697b9",
   "metadata": {},
   "source": [
    "# Predict google map review dataset \n",
    "## model\n",
    "- kcbert\n",
    "- fine-tuned with naver shopping review dataset (200,000개)\n",
    "- train 5 epochs\n",
    "- 0.97 accuracy\n",
    "\n",
    "## dataset\n",
    "- google map review of tourist places in Daejeon, Korea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a14c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, DistributedSampler, random_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from pytorch_lightning.core.lightning import LightningModule \n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.metrics.functional import accuracy, precision, recall\n",
    "from transformers import AdamW, BertForSequenceClassification, AdamW, BertConfig, AutoTokenizer, BertTokenizer, TrainingArguments\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac6a503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c76ca1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pj_path = os.getenv('HOME') + '/Projects/JeongCheck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74c09496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8408\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>search</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>미샤</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2주 전</td>\n",
       "      <td>1.0</td>\n",
       "      <td>여기는 갈 때마다 새로운 느낌이 야 즐거운 시간이 되었습니다</td>\n",
       "      <td>장태산자연휴양림메타세콰이어산림욕장</td>\n",
       "      <td>jangtaesan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gyang gree young</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3주 전</td>\n",
       "      <td>1.0</td>\n",
       "      <td>하늘 보고 누워 힐링하기 너무 좋은 곳이에요</td>\n",
       "      <td>장태산자연휴양림메타세콰이어산림욕장</td>\n",
       "      <td>jangtaesan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>박진수</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3달 전</td>\n",
       "      <td>1.0</td>\n",
       "      <td>잘 정리된 메타세쿼이아 숲에서 산림욕하기 좋은 곳으로 둘레길 걷기와 전망대까지 가벼...</td>\n",
       "      <td>장태산자연휴양림메타세콰이어산림욕장</td>\n",
       "      <td>jangtaesan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sh Choi</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7달 전</td>\n",
       "      <td>1.0</td>\n",
       "      <td>산책하기 너무 좋은 명소</td>\n",
       "      <td>장태산자연휴양림메타세콰이어산림욕장</td>\n",
       "      <td>jangtaesan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>박은선</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>1.0</td>\n",
       "      <td>주말 마자 애정 하는 장태산 나들이 단풍도 예뻐요</td>\n",
       "      <td>장태산자연휴양림메타세콰이어산림욕장</td>\n",
       "      <td>jangtaesan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ratings  date  label  \\\n",
       "name                                     \n",
       "미샤                    4.0  2주 전    1.0   \n",
       "Gyang gree young      5.0  3주 전    1.0   \n",
       "박진수                   5.0  3달 전    1.0   \n",
       "Sh Choi               5.0  7달 전    1.0   \n",
       "박은선                   5.0  1년 전    1.0   \n",
       "\n",
       "                                                            comment  \\\n",
       "name                                                                  \n",
       "미샤                                여기는 갈 때마다 새로운 느낌이 야 즐거운 시간이 되었습니다   \n",
       "Gyang gree young                           하늘 보고 누워 힐링하기 너무 좋은 곳이에요   \n",
       "박진수               잘 정리된 메타세쿼이아 숲에서 산림욕하기 좋은 곳으로 둘레길 걷기와 전망대까지 가벼...   \n",
       "Sh Choi                                               산책하기 너무 좋은 명소   \n",
       "박은선                                     주말 마자 애정 하는 장태산 나들이 단풍도 예뻐요   \n",
       "\n",
       "                              search     keyword  \n",
       "name                                              \n",
       "미샤                장태산자연휴양림메타세콰이어산림욕장  jangtaesan  \n",
       "Gyang gree young  장태산자연휴양림메타세콰이어산림욕장  jangtaesan  \n",
       "박진수               장태산자연휴양림메타세콰이어산림욕장  jangtaesan  \n",
       "Sh Choi           장태산자연휴양림메타세콰이어산림욕장  jangtaesan  \n",
       "박은선               장태산자연휴양림메타세콰이어산림욕장  jangtaesan  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv(pj_path + '/crawling_data/google_reviews.csv', index_col=0)\n",
    "print(len(test_set))\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4cdd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_make_df(place, data):\n",
    "    print(f'##### {place} #####')\n",
    "    print(data.head)\n",
    "    print(f'{place} len :', len(data))\n",
    "    \n",
    "    if any(data.isna().sum()) == True:\n",
    "        test_set.dropna(inplace=True)\n",
    "    \n",
    "    print('nan values check :', any(data.isna().sum()))\n",
    "    \n",
    "    neutral_portion = len(data[data.label==2]) / len(data)\n",
    "    print('neutral label portion :', neutral_portion)\n",
    "    \n",
    "    new_data = data[data.label != 2]\n",
    "    data = new_data\n",
    "    print('final length of data :', len(new_data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2ebb5272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### total #####\n",
      "<bound method NDFrame.head of                   ratings  date  label  \\\n",
      "name                                     \n",
      "미샤                    4.0  2주 전    1.0   \n",
      "Gyang gree young      5.0  3주 전    1.0   \n",
      "박진수                   5.0  3달 전    1.0   \n",
      "Sh Choi               5.0  7달 전    1.0   \n",
      "박은선                   5.0  1년 전    1.0   \n",
      "...                   ...   ...    ...   \n",
      "NaN                   NaN   NaN    NaN   \n",
      "NaN                   NaN   NaN    NaN   \n",
      "NaN                   NaN   NaN    NaN   \n",
      "NaN                   NaN   NaN    NaN   \n",
      "NaN                   NaN   NaN    NaN   \n",
      "\n",
      "                                                            comment  \\\n",
      "name                                                                  \n",
      "미샤                                여기는 갈 때마다 새로운 느낌이 야 즐거운 시간이 되었습니다   \n",
      "Gyang gree young                           하늘 보고 누워 힐링하기 너무 좋은 곳이에요   \n",
      "박진수               잘 정리된 메타세쿼이아 숲에서 산림욕하기 좋은 곳으로 둘레길 걷기와 전망대까지 가벼...   \n",
      "Sh Choi                                               산책하기 너무 좋은 명소   \n",
      "박은선                                     주말 마자 애정 하는 장태산 나들이 단풍도 예뻐요   \n",
      "...                                                             ...   \n",
      "NaN                                                             NaN   \n",
      "NaN                                                             NaN   \n",
      "NaN                                                             NaN   \n",
      "NaN                                                             NaN   \n",
      "NaN                                                               0   \n",
      "\n",
      "                              search     keyword  \n",
      "name                                              \n",
      "미샤                장태산자연휴양림메타세콰이어산림욕장  jangtaesan  \n",
      "Gyang gree young  장태산자연휴양림메타세콰이어산림욕장  jangtaesan  \n",
      "박진수               장태산자연휴양림메타세콰이어산림욕장  jangtaesan  \n",
      "Sh Choi           장태산자연휴양림메타세콰이어산림욕장  jangtaesan  \n",
      "박은선               장태산자연휴양림메타세콰이어산림욕장  jangtaesan  \n",
      "...                              ...         ...  \n",
      "NaN                              NaN         NaN  \n",
      "NaN                              NaN         NaN  \n",
      "NaN                              NaN         NaN  \n",
      "NaN                              NaN         NaN  \n",
      "NaN                              NaN         NaN  \n",
      "\n",
      "[8408 rows x 6 columns]>\n",
      "total len : 8408\n",
      "nan values check : False\n",
      "neutral label portion : 0.004664629242399871\n",
      "final length of data : 6188\n"
     ]
    }
   ],
   "source": [
    "test_set = check_make_df('total', test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51e8e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68eb2bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model_kc = BertForSequenceClassification.from_pretrained(\n",
    "    \"beomi/kcbert-base\",\n",
    "    num_labels = 2, \n",
    "                    \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model_nsmc = BertForSequenceClassification.from_pretrained(\n",
    "    pj_path + \"/checkpoint-1500\",\n",
    "    num_labels = 2, \n",
    "                    \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "model_sent = BertForSequenceClassification.from_pretrained(\n",
    "    pj_path + \"/bert_model/checkpoint-2000\",\n",
    "    num_labels = 2, \n",
    "                    \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1afe405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_check(model):\n",
    "    params = list(model.named_parameters())\n",
    "\n",
    "    print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "    print('==== Embedding Layer ====\\n')\n",
    "\n",
    "    for p in params[0:5]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "    for p in params[5:21]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "    for p in params[-4:]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97b46eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30000, 768)\n",
      "bert.embeddings.position_embeddings.weight                (300, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n",
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30000, 768)\n",
      "bert.embeddings.position_embeddings.weight                (300, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n",
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30000, 768)\n",
      "bert.embeddings.position_embeddings.weight                (300, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "param_check(model_kc)\n",
    "param_check(model_nsmc)\n",
    "param_check(model_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0381e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model_kc = model_kc.to(device)\n",
    "model_nsmc = model_nsmc.to(device)\n",
    "model_sent = model_sent.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4e6d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_data(sentences):\n",
    "\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "    MAX_LEN = 64\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    \n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "        \n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "679da37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentences(sentences, model):\n",
    " \n",
    "    # 평가모드로 변경!!!!!\n",
    "    model.eval()\n",
    "\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b0eb25",
   "metadata": {},
   "source": [
    "## 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5fcda091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "\n",
    "    df.document=df.comment.replace('[^A-Za-zㄱ-ㅎㅏ-ㅣ가-힣]+','')\n",
    "\n",
    "    return df\n",
    "\n",
    "# result = preprocessing(gr_data)\n",
    "# result = result.dropna()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2553cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성분석할 comment 추출 \n",
    "def export_com(preprocessed_df):\n",
    "    sens =[]\n",
    "    for sen in preprocessed_df.comment:\n",
    "        sens.append(sen)\n",
    "    print('check length :', len(sens), len(preprocessed_df)) # 개수 확인 \n",
    "    print('sample sentence :', sens[1])\n",
    "    return sens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4155f22",
   "metadata": {},
   "source": [
    "label : neg(0) p(1) neut(2)\n",
    "pred : idx 0, 1, 2 -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26c2f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predicted_label(sen, model):\n",
    "    sen = [sen]\n",
    "    score = test_sentences(sen, model)\n",
    "    result = np.argmax(score)\n",
    "\n",
    "    if result == 0:   # negative \n",
    "        return 0\n",
    "    elif result == 1: # positive\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cef352b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model, df, place_name):\n",
    "    result = preprocessing(df)\n",
    "    result = result.dropna()\n",
    "    \n",
    "    sens = export_com(result)\n",
    "    \n",
    "    scores_data=[]\n",
    "    for sen in sens:\n",
    "        scores_data.append(make_predicted_label(sen, model))\n",
    "        \n",
    "    df['pred'] = scores_data    \n",
    "    \n",
    "    cor = df[df.label == df.pred]\n",
    "    uncor = df[df.label != df.pred]\n",
    "    \n",
    "    print('correct prediction num :', len(cor))\n",
    "    print('uncorrect prediction num :', len(uncor))\n",
    "    print('correct label check :' ,set(cor.label))\n",
    "    \n",
    "    df.to_csv(pj_path + f'/prediction_data/{place_name}_pred.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271b330",
   "metadata": {},
   "source": [
    "## Loss (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c8c01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "304d7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import math\n",
    "    \n",
    "    rmse_label = math.sqrt(mean_squared_error(y, y_pred))\n",
    "    print('rmse of label :', rmse_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e51d69",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ccc4cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y, y_pred, total):\n",
    "    correct = (y_pred == y).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the {total} test text: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea034b",
   "metadata": {},
   "source": [
    "## F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5bfd06b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "40930501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y, y_pred):\n",
    "    score = f1_score(y, y_pred)\n",
    "    report = classification_report(y, y_pred)\n",
    "    \n",
    "    print('## f1-score ##')\n",
    "    print('f1 score :', score)\n",
    "    print('## classification report ##')\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95137d5d",
   "metadata": {},
   "source": [
    "## calculate performance\n",
    "- RMSE\n",
    "- Accuracy\n",
    "- f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "de151e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_perform(df):\n",
    "    y = df.label\n",
    "    y_pred = df.pred\n",
    "    if len(y) == len(y_pred):\n",
    "        total = len(y)\n",
    "        print('same length')\n",
    "        print('label length :', total)\n",
    "    else:\n",
    "        print('different length')\n",
    "    \n",
    "    rmse(y, y_pred)\n",
    "    acc(y, y_pred, total)\n",
    "    f1(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1b19c4",
   "metadata": {},
   "source": [
    "## 모델 별 성능 지표 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bd6508e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_kc, model_nsmc, model_sent]\n",
    "model_list_idx = [[idx, model] for idx, model in enumerate(model_list)]\n",
    "model_name = ['model_kc', 'model_nsmc', 'model_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0601f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== model_kc predict .... =====\n",
      "check length : 6188 6188\n",
      "sample sentence : 하늘 보고 누워 힐링하기 너무 좋은 곳이에요\n",
      "correct prediction num : 805\n",
      "uncorrect prediction num : 5383\n",
      "correct label check : {0.0, 1.0}\n",
      "same length\n",
      "label length : 6188\n",
      "rmse of label : 0.9326893921678553\n",
      "Accuracy of the network on the 6188 test text: 13 %\n",
      "## f1-score ##\n",
      "f1 score : 0.009567617295308188\n",
      "## classification report ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.13      0.99      0.22       785\n",
      "         1.0       0.81      0.00      0.01      5403\n",
      "\n",
      "    accuracy                           0.13      6188\n",
      "   macro avg       0.47      0.50      0.12      6188\n",
      "weighted avg       0.73      0.13      0.04      6188\n",
      "\n",
      "===== model_nsmc predict .... =====\n",
      "check length : 6188 6188\n",
      "sample sentence : 하늘 보고 누워 힐링하기 너무 좋은 곳이에요\n",
      "correct prediction num : 5001\n",
      "uncorrect prediction num : 1187\n",
      "correct label check : {0.0, 1.0}\n",
      "same length\n",
      "label length : 6188\n",
      "rmse of label : 0.43797589317147767\n",
      "Accuracy of the network on the 6188 test text: 80 %\n",
      "## f1-score ##\n",
      "f1 score : 0.8855683023233394\n",
      "## classification report ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.52      0.41       785\n",
      "         1.0       0.92      0.85      0.89      5403\n",
      "\n",
      "    accuracy                           0.81      6188\n",
      "   macro avg       0.63      0.68      0.65      6188\n",
      "weighted avg       0.85      0.81      0.82      6188\n",
      "\n",
      "===== model_sent predict .... =====\n",
      "check length : 6188 6188\n",
      "sample sentence : 하늘 보고 누워 힐링하기 너무 좋은 곳이에요\n",
      "correct prediction num : 4930\n",
      "uncorrect prediction num : 1258\n",
      "correct label check : {0.0, 1.0}\n",
      "same length\n",
      "label length : 6188\n",
      "rmse of label : 0.4508843568995306\n",
      "Accuracy of the network on the 6188 test text: 79 %\n",
      "## f1-score ##\n",
      "f1 score : 0.8738214643931795\n",
      "## classification report ##\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.73      0.48       785\n",
      "         1.0       0.95      0.81      0.87      5403\n",
      "\n",
      "    accuracy                           0.80      6188\n",
      "   macro avg       0.65      0.77      0.68      6188\n",
      "weighted avg       0.88      0.80      0.82      6188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model, name in zip(model_list_idx, model_name):\n",
    "    print(f'===== {name} predict .... =====')\n",
    "    data = predict_label(model[-1], test_set, model[0])\n",
    "    cal_perform(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
