{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "985f7dce",
   "metadata": {},
   "source": [
    "# kcbert Fine-tune with Naver Shopping Review Data\n",
    "\n",
    "- kcbert 모델을 네이버 쇼핑 리뷰 데이터를 이용해 파인튜닝합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc58023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW, BertForSequenceClassification\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf6f3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5737d",
   "metadata": {},
   "source": [
    "# data load \n",
    "- fine-tuning 할 데이터를 불러옵니다.\n",
    "- 네이버 쇼핑 리뷰 데이터\n",
    "    - 언어: 한국어\n",
    "    - 출처: 네이버 쇼핑 (https://shopping.naver.com/)\n",
    "    - 수집 기간: 2020.06~2020.07\n",
    "    - 데이터 건수: 20만 건\n",
    "    - 데이터 출처: (https://github.com/bab2min/corpus/tree/master/sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a927e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "\n",
    "file_path = os.getenv('HOME') + '/Projects/crawling_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a05aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_data = pd.read_csv(file_path + '/naver_shopping.txt', delimiter = '\\t', names =['label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c04565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ns_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0987f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      5                                            배공빠르고 굿\n",
       "1      2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
       "2      5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
       "3      2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
       "4      5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2033f",
   "metadata": {},
   "source": [
    "- label 5, 4 = 긍정    -> 1\n",
    "- label 1, 2 = 부정    -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a48b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_data['label'] = ns_data['label'].apply(lambda row : 1 if row == 5 or row == 4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef45dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>배공빠르고 굿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1                                            배공빠르고 굿\n",
       "1      0                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
       "2      1  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
       "3      0  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
       "4      1                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79cc07b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, '민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_data.iloc[4, :].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2ab721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns_data.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c1b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class createDataset(Dataset):\n",
    "  \n",
    "    def __init__(self, csv_file):\n",
    "        # 일부 값중에 NaN이 있음...\n",
    "        self.dataset = csv_file.dropna(axis=0) \n",
    "        # 중복제거\n",
    "        self.dataset.drop_duplicates(subset=['text'], inplace=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")\n",
    "\n",
    "        print(self.dataset.describe())\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset.iloc[idx, :].values\n",
    "        y = row[0]\n",
    "        text = row[1]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            text, \n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            max_length=64,\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True\n",
    "            )\n",
    "\n",
    "        input_ids = inputs['input_ids'][0]\n",
    "        attention_mask = inputs['attention_mask'][0]\n",
    "\n",
    "        return input_ids, attention_mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f55f5a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               label\n",
      "count  199908.000000\n",
      "mean        0.499995\n",
      "std         0.500001\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = createDataset(ns_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4958684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"beomi/kcbert-base\", num_labels = 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "223a98a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(300, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 레이어 보기\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e34c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d363d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81a490ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e247f5f5a3564f9c9c3e483b631d6dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 22.41069170832634 Accuracy: tensor(0.9155, device='cuda:0')\n",
      "Batch Loss: 45.24523111432791 Accuracy: tensor(0.9159, device='cuda:0')\n",
      "Batch Loss: 66.17004200816154 Accuracy: tensor(0.9182, device='cuda:0')\n",
      "Batch Loss: 86.33263068646193 Accuracy: tensor(0.9210, device='cuda:0')\n",
      "Batch Loss: 108.22352690249681 Accuracy: tensor(0.9208, device='cuda:0')\n",
      "Batch Loss: 128.34162107110023 Accuracy: tensor(0.9217, device='cuda:0')\n",
      "Batch Loss: 148.72233647853136 Accuracy: tensor(0.9226, device='cuda:0')\n",
      "Batch Loss: 169.24662873148918 Accuracy: tensor(0.9230, device='cuda:0')\n",
      "Batch Loss: 189.3186566606164 Accuracy: tensor(0.9231, device='cuda:0')\n",
      "Batch Loss: 208.03979951515794 Accuracy: tensor(0.9239, device='cuda:0')\n",
      "Batch Loss: 226.78177179023623 Accuracy: tensor(0.9245, device='cuda:0')\n",
      "Batch Loss: 246.4026281349361 Accuracy: tensor(0.9249, device='cuda:0')\n",
      "Batch Loss: 265.6738530881703 Accuracy: tensor(0.9253, device='cuda:0')\n",
      "Batch Loss: 284.33616726472974 Accuracy: tensor(0.9258, device='cuda:0')\n",
      "Batch Loss: 303.6099249869585 Accuracy: tensor(0.9261, device='cuda:0')\n",
      "Batch Loss: 323.1336243338883 Accuracy: tensor(0.9264, device='cuda:0')\n",
      "Batch Loss: 341.9861735031009 Accuracy: tensor(0.9268, device='cuda:0')\n",
      "Batch Loss: 361.6786337196827 Accuracy: tensor(0.9270, device='cuda:0')\n",
      "Batch Loss: 380.3481900244951 Accuracy: tensor(0.9272, device='cuda:0')\n",
      "Batch Loss: 398.7316825762391 Accuracy: tensor(0.9275, device='cuda:0')\n",
      "Batch Loss: 417.3796776048839 Accuracy: tensor(0.9278, device='cuda:0')\n",
      "Batch Loss: 435.71560184285045 Accuracy: tensor(0.9280, device='cuda:0')\n",
      "Batch Loss: 453.7800620608032 Accuracy: tensor(0.9283, device='cuda:0')\n",
      "Batch Loss: 473.5150398388505 Accuracy: tensor(0.9282, device='cuda:0')\n",
      "Batch Loss: 493.0473895035684 Accuracy: tensor(0.9281, device='cuda:0')\n",
      "Batch Loss: 511.30812249332666 Accuracy: tensor(0.9283, device='cuda:0')\n",
      "Batch Loss: 529.5924984291196 Accuracy: tensor(0.9285, device='cuda:0')\n",
      "Batch Loss: 547.4173801057041 Accuracy: tensor(0.9288, device='cuda:0')\n",
      "Batch Loss: 565.3597359918058 Accuracy: tensor(0.9290, device='cuda:0')\n",
      "Batch Loss: 583.4835208617151 Accuracy: tensor(0.9292, device='cuda:0')\n",
      "Batch Loss: 601.9949501566589 Accuracy: tensor(0.9292, device='cuda:0')\n",
      "Train Loss: 606.3243498317897 Accuracy: tensor(0.9292, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827beea486e641d3a75b7ef4c1388be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 15.535484116524458 Accuracy: tensor(0.9445, device='cuda:0')\n",
      "Batch Loss: 30.850275671109557 Accuracy: tensor(0.9457, device='cuda:0')\n",
      "Batch Loss: 45.80500068701804 Accuracy: tensor(0.9465, device='cuda:0')\n",
      "Batch Loss: 61.41094231419265 Accuracy: tensor(0.9467, device='cuda:0')\n",
      "Batch Loss: 77.2916609402746 Accuracy: tensor(0.9455, device='cuda:0')\n",
      "Batch Loss: 92.56482781097293 Accuracy: tensor(0.9453, device='cuda:0')\n",
      "Batch Loss: 108.13161433115602 Accuracy: tensor(0.9458, device='cuda:0')\n",
      "Batch Loss: 123.26839564926922 Accuracy: tensor(0.9454, device='cuda:0')\n",
      "Batch Loss: 138.81923618353903 Accuracy: tensor(0.9456, device='cuda:0')\n",
      "Batch Loss: 154.8282688651234 Accuracy: tensor(0.9455, device='cuda:0')\n",
      "Batch Loss: 169.97794582135975 Accuracy: tensor(0.9456, device='cuda:0')\n",
      "Batch Loss: 184.3544636555016 Accuracy: tensor(0.9460, device='cuda:0')\n",
      "Batch Loss: 201.51122590899467 Accuracy: tensor(0.9455, device='cuda:0')\n",
      "Batch Loss: 217.35330041870475 Accuracy: tensor(0.9455, device='cuda:0')\n",
      "Batch Loss: 232.6749441176653 Accuracy: tensor(0.9456, device='cuda:0')\n",
      "Batch Loss: 247.23880906030536 Accuracy: tensor(0.9458, device='cuda:0')\n",
      "Batch Loss: 263.87554569914937 Accuracy: tensor(0.9455, device='cuda:0')\n",
      "Batch Loss: 279.8211712576449 Accuracy: tensor(0.9454, device='cuda:0')\n",
      "Batch Loss: 296.00377183780074 Accuracy: tensor(0.9451, device='cuda:0')\n",
      "Batch Loss: 311.39519591256976 Accuracy: tensor(0.9451, device='cuda:0')\n",
      "Batch Loss: 327.0855198428035 Accuracy: tensor(0.9451, device='cuda:0')\n",
      "Batch Loss: 341.591914113611 Accuracy: tensor(0.9451, device='cuda:0')\n",
      "Batch Loss: 357.72803960740566 Accuracy: tensor(0.9449, device='cuda:0')\n",
      "Batch Loss: 373.8516000434756 Accuracy: tensor(0.9448, device='cuda:0')\n",
      "Batch Loss: 390.12083506956697 Accuracy: tensor(0.9447, device='cuda:0')\n",
      "Batch Loss: 405.54172814264894 Accuracy: tensor(0.9446, device='cuda:0')\n",
      "Batch Loss: 420.4706471078098 Accuracy: tensor(0.9447, device='cuda:0')\n",
      "Batch Loss: 435.02799898572266 Accuracy: tensor(0.9449, device='cuda:0')\n",
      "Batch Loss: 450.2771561089903 Accuracy: tensor(0.9449, device='cuda:0')\n",
      "Batch Loss: 465.308953685686 Accuracy: tensor(0.9450, device='cuda:0')\n",
      "Batch Loss: 480.4610010366887 Accuracy: tensor(0.9451, device='cuda:0')\n",
      "Train Loss: 484.34553881548345 Accuracy: tensor(0.9451, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813a8b8da0f14aac8825d7b2c38f344c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 13.101665252819657 Accuracy: tensor(0.9581, device='cuda:0')\n",
      "Batch Loss: 26.02288237400353 Accuracy: tensor(0.9570, device='cuda:0')\n",
      "Batch Loss: 38.490024676546454 Accuracy: tensor(0.9574, device='cuda:0')\n",
      "Batch Loss: 50.440011670812964 Accuracy: tensor(0.9577, device='cuda:0')\n",
      "Batch Loss: 61.586201997473836 Accuracy: tensor(0.9588, device='cuda:0')\n",
      "Batch Loss: 73.49722432158887 Accuracy: tensor(0.9585, device='cuda:0')\n",
      "Batch Loss: 84.40155727043748 Accuracy: tensor(0.9591, device='cuda:0')\n",
      "Batch Loss: 96.59836361557245 Accuracy: tensor(0.9591, device='cuda:0')\n",
      "Batch Loss: 109.77462154999375 Accuracy: tensor(0.9585, device='cuda:0')\n",
      "Batch Loss: 121.69824912026525 Accuracy: tensor(0.9584, device='cuda:0')\n",
      "Batch Loss: 133.5923726912588 Accuracy: tensor(0.9583, device='cuda:0')\n",
      "Batch Loss: 145.53878804296255 Accuracy: tensor(0.9582, device='cuda:0')\n",
      "Batch Loss: 158.25548366643488 Accuracy: tensor(0.9578, device='cuda:0')\n",
      "Batch Loss: 170.17795721068978 Accuracy: tensor(0.9577, device='cuda:0')\n",
      "Batch Loss: 183.42699852958322 Accuracy: tensor(0.9574, device='cuda:0')\n",
      "Batch Loss: 194.62079709768295 Accuracy: tensor(0.9576, device='cuda:0')\n",
      "Batch Loss: 208.6184164211154 Accuracy: tensor(0.9573, device='cuda:0')\n",
      "Batch Loss: 221.3406679648906 Accuracy: tensor(0.9570, device='cuda:0')\n",
      "Batch Loss: 234.8934879694134 Accuracy: tensor(0.9568, device='cuda:0')\n",
      "Batch Loss: 247.2550390586257 Accuracy: tensor(0.9570, device='cuda:0')\n",
      "Batch Loss: 260.14568860828876 Accuracy: tensor(0.9570, device='cuda:0')\n",
      "Batch Loss: 272.47757521271706 Accuracy: tensor(0.9571, device='cuda:0')\n",
      "Batch Loss: 284.957657776773 Accuracy: tensor(0.9570, device='cuda:0')\n",
      "Batch Loss: 297.7280024923384 Accuracy: tensor(0.9569, device='cuda:0')\n",
      "Batch Loss: 310.7800785936415 Accuracy: tensor(0.9567, device='cuda:0')\n",
      "Batch Loss: 323.40705397352576 Accuracy: tensor(0.9567, device='cuda:0')\n",
      "Batch Loss: 336.54510874673724 Accuracy: tensor(0.9567, device='cuda:0')\n",
      "Batch Loss: 349.03201785869896 Accuracy: tensor(0.9567, device='cuda:0')\n",
      "Batch Loss: 361.6229350846261 Accuracy: tensor(0.9566, device='cuda:0')\n",
      "Batch Loss: 374.6550462599844 Accuracy: tensor(0.9565, device='cuda:0')\n",
      "Batch Loss: 387.2730506360531 Accuracy: tensor(0.9565, device='cuda:0')\n",
      "Train Loss: 390.2278171814978 Accuracy: tensor(0.9565, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9ebab319834010a45bab0b218d1d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 9.88232403434813 Accuracy: tensor(0.9692, device='cuda:0')\n",
      "Batch Loss: 19.2182597797364 Accuracy: tensor(0.9688, device='cuda:0')\n",
      "Batch Loss: 28.695704546757042 Accuracy: tensor(0.9682, device='cuda:0')\n",
      "Batch Loss: 37.68656265642494 Accuracy: tensor(0.9682, device='cuda:0')\n",
      "Batch Loss: 47.34520173911005 Accuracy: tensor(0.9680, device='cuda:0')\n",
      "Batch Loss: 56.70309564564377 Accuracy: tensor(0.9683, device='cuda:0')\n",
      "Batch Loss: 65.66183421108872 Accuracy: tensor(0.9685, device='cuda:0')\n",
      "Batch Loss: 75.62898162472993 Accuracy: tensor(0.9684, device='cuda:0')\n",
      "Batch Loss: 85.59384157322347 Accuracy: tensor(0.9683, device='cuda:0')\n",
      "Batch Loss: 95.50813751854002 Accuracy: tensor(0.9683, device='cuda:0')\n",
      "Batch Loss: 106.0159612474963 Accuracy: tensor(0.9678, device='cuda:0')\n",
      "Batch Loss: 115.517677645199 Accuracy: tensor(0.9677, device='cuda:0')\n",
      "Batch Loss: 125.4143646331504 Accuracy: tensor(0.9676, device='cuda:0')\n",
      "Batch Loss: 134.55193828884512 Accuracy: tensor(0.9677, device='cuda:0')\n",
      "Batch Loss: 143.35612482205033 Accuracy: tensor(0.9677, device='cuda:0')\n",
      "Batch Loss: 152.85752577707171 Accuracy: tensor(0.9678, device='cuda:0')\n",
      "Batch Loss: 163.01758086681366 Accuracy: tensor(0.9676, device='cuda:0')\n",
      "Batch Loss: 172.54817719757557 Accuracy: tensor(0.9676, device='cuda:0')\n",
      "Batch Loss: 181.84912483021617 Accuracy: tensor(0.9676, device='cuda:0')\n",
      "Batch Loss: 191.6189297158271 Accuracy: tensor(0.9675, device='cuda:0')\n",
      "Batch Loss: 201.6269311560318 Accuracy: tensor(0.9674, device='cuda:0')\n",
      "Batch Loss: 212.65926793497056 Accuracy: tensor(0.9673, device='cuda:0')\n",
      "Batch Loss: 223.225466334261 Accuracy: tensor(0.9671, device='cuda:0')\n",
      "Batch Loss: 234.00538047682494 Accuracy: tensor(0.9670, device='cuda:0')\n",
      "Batch Loss: 244.08533575106412 Accuracy: tensor(0.9670, device='cuda:0')\n",
      "Batch Loss: 253.55537697579712 Accuracy: tensor(0.9670, device='cuda:0')\n",
      "Batch Loss: 262.488039534539 Accuracy: tensor(0.9671, device='cuda:0')\n",
      "Batch Loss: 273.29250718839467 Accuracy: tensor(0.9669, device='cuda:0')\n",
      "Batch Loss: 283.8619082570076 Accuracy: tensor(0.9668, device='cuda:0')\n",
      "Batch Loss: 293.924839630723 Accuracy: tensor(0.9668, device='cuda:0')\n",
      "Batch Loss: 303.8980010803789 Accuracy: tensor(0.9668, device='cuda:0')\n",
      "Train Loss: 306.77541410923004 Accuracy: tensor(0.9668, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2128d9b74f504499843301fcc601fa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 7.446292203851044 Accuracy: tensor(0.9770, device='cuda:0')\n",
      "Batch Loss: 16.399508429691195 Accuracy: tensor(0.9737, device='cuda:0')\n",
      "Batch Loss: 22.999107289128006 Accuracy: tensor(0.9749, device='cuda:0')\n",
      "Batch Loss: 30.496809924952686 Accuracy: tensor(0.9747, device='cuda:0')\n",
      "Batch Loss: 37.78622882813215 Accuracy: tensor(0.9747, device='cuda:0')\n",
      "Batch Loss: 45.36345586832613 Accuracy: tensor(0.9748, device='cuda:0')\n",
      "Batch Loss: 51.712055205367506 Accuracy: tensor(0.9755, device='cuda:0')\n",
      "Batch Loss: 59.698407934978604 Accuracy: tensor(0.9751, device='cuda:0')\n",
      "Batch Loss: 66.54481840599328 Accuracy: tensor(0.9752, device='cuda:0')\n",
      "Batch Loss: 73.58150220476091 Accuracy: tensor(0.9753, device='cuda:0')\n",
      "Batch Loss: 81.37639909144491 Accuracy: tensor(0.9752, device='cuda:0')\n",
      "Batch Loss: 90.43283574096859 Accuracy: tensor(0.9747, device='cuda:0')\n",
      "Batch Loss: 98.5108848027885 Accuracy: tensor(0.9745, device='cuda:0')\n",
      "Batch Loss: 106.78875660896301 Accuracy: tensor(0.9742, device='cuda:0')\n",
      "Batch Loss: 115.02834596391767 Accuracy: tensor(0.9741, device='cuda:0')\n",
      "Batch Loss: 122.60855080746114 Accuracy: tensor(0.9741, device='cuda:0')\n",
      "Batch Loss: 130.33890025829896 Accuracy: tensor(0.9742, device='cuda:0')\n",
      "Batch Loss: 138.8144145575352 Accuracy: tensor(0.9741, device='cuda:0')\n",
      "Batch Loss: 147.0020519210957 Accuracy: tensor(0.9741, device='cuda:0')\n",
      "Batch Loss: 154.9366983496584 Accuracy: tensor(0.9739, device='cuda:0')\n",
      "Batch Loss: 162.04598336992785 Accuracy: tensor(0.9740, device='cuda:0')\n",
      "Batch Loss: 170.28461900586262 Accuracy: tensor(0.9740, device='cuda:0')\n",
      "Batch Loss: 178.0519679444842 Accuracy: tensor(0.9739, device='cuda:0')\n",
      "Batch Loss: 185.94819870451465 Accuracy: tensor(0.9740, device='cuda:0')\n",
      "Batch Loss: 193.17940419446677 Accuracy: tensor(0.9740, device='cuda:0')\n",
      "Batch Loss: 200.67183940391988 Accuracy: tensor(0.9740, device='cuda:0')\n",
      "Batch Loss: 208.23043071851134 Accuracy: tensor(0.9740, device='cuda:0')\n",
      "Batch Loss: 216.49424648005515 Accuracy: tensor(0.9739, device='cuda:0')\n",
      "Batch Loss: 224.6292603481561 Accuracy: tensor(0.9739, device='cuda:0')\n",
      "Batch Loss: 232.97966606821865 Accuracy: tensor(0.9738, device='cuda:0')\n",
      "Batch Loss: 240.85550248343498 Accuracy: tensor(0.9738, device='cuda:0')\n",
      "Train Loss: 242.86972376238555 Accuracy: tensor(0.9738, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batches = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
    "        loss = F.cross_entropy(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        correct += (predicted == y_batch).sum()\n",
    "        total += len(y_batch)\n",
    "\n",
    "        batches += 1\n",
    "        if batches % 100 == 0:\n",
    "            print(\"Batch Loss:\", total_loss, \"Accuracy:\", correct.float() / total)\n",
    "  \n",
    "    losses.append(total_loss)\n",
    "    accuracies.append(correct.float() / total)\n",
    "    print(\"Train Loss:\", total_loss, \"Accuracy:\", correct.float() / total)\n",
    "    acc = correct.float() / total\n",
    "    \n",
    "    # 모델 저장하기\n",
    "    torch.save(model.state_dict(), file_path + f\"/model_{i}_{acc}acc.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57f710e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([606.3243498317897,\n",
       "  484.34553881548345,\n",
       "  390.2278171814978,\n",
       "  306.77541410923004,\n",
       "  242.86972376238555],\n",
       " [tensor(0.9292, device='cuda:0'),\n",
       "  tensor(0.9451, device='cuda:0'),\n",
       "  tensor(0.9565, device='cuda:0'),\n",
       "  tensor(0.9668, device='cuda:0'),\n",
       "  tensor(0.9738, device='cuda:0')])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses, accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
