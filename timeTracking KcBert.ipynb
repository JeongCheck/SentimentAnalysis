{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction timetracking for o_world data \n",
    "\n",
    "1. Manipulate data with ndarray.\n",
    "2. Create a neural network.\n",
    "3. Automatic differentiation with autograd.\n",
    "4. Train the neural network.\n",
    "5. Predict with a pre-trained model.\n",
    "6. Use GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "#파이토치 다운그레이드  \n",
    "#conda install pytorch==1.5.1 torchvision==0.6.1 -c pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers           4.2.2\n",
      "pytorch-lightning      1.2.3\n",
      "torch                  1.8.1\n",
      "torchmetrics           0.3.2\n",
      "torchvision            0.6.0a0+35d732a\n",
      "numpy                  1.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep transformers\n",
    "!pip list | grep torch\n",
    "!pip list | grep numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, DistributedSampler, random_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from pytorch_lightning.core.lightning import LightningModule \n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.metrics.functional import accuracy, precision, recall\n",
    "from transformers.models.bert.modeling_bert import BertModel\n",
    "from transformers import AdamW, BertForSequenceClassification, AdamW, BertConfig, AutoTokenizer, BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "#ImportError: cannot import name 'SAVE_STATE_WARNING'\n",
    "#SAVE_STATE_WARNING from PyTorch, only exists in 1.5.0 \n",
    "#downgrade pytorch version to 1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # 파이토치에 GPU 할당    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델과 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#토크나이저: kcbert\n",
    "from transformers import AutoModelWithLMHead\n",
    "model_name = \"beomi/kcbert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#bert = AutoModelWithLMHead.from_pretrained(\"beomi/kcbert-base\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"beomi/kcbert-base\")\n",
    "#model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2) #label 수를 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드 후 콘텐츠만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[150000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df[0:120000]\n",
    "valid_set = df[120000:135000]\n",
    "test_set  = df[135000:150000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "15000\n",
      "15000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(valid_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, document, label, tokenizer):\n",
    "        self.document    = document\n",
    "        self.label = label\n",
    "        self.tokenizer  = tokenizer\n",
    "        self.max_len    = tokenizer.model_max_length\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.document)\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        document = str(self.document[index])\n",
    "        label = self.label[index]\n",
    "\n",
    "        encoded_review = self.tokenizer.encode_plus(\n",
    "            document,\n",
    "            add_special_tokens    = True,\n",
    "            max_length            = self.max_len,\n",
    "            return_token_type_ids = False,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors        = \"pt\",\n",
    "            padding               = \"max_length\",\n",
    "            truncation            = True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoded_review['input_ids'][0],\n",
    "            'attention_mask': encoded_review['attention_mask'][0],\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 300]) torch.Size([16, 300])\n"
     ]
    }
   ],
   "source": [
    "train_set_dataset = TheDataset(\n",
    "    document    = train_set.document.tolist(),\n",
    "    label = train_set.label.tolist(),\n",
    "    tokenizer  = tokenizer,\n",
    ")\n",
    "\n",
    "valid_set_dataset = TheDataset(\n",
    "    document    = valid_set.document.tolist(),\n",
    "    label = valid_set.label.tolist(),\n",
    "    tokenizer  = tokenizer,\n",
    ")\n",
    "\n",
    "# Create DataLoader for train/validation sets.\n",
    "train_set_dataloader = torch.utils.data.DataLoader(\n",
    "    train_set_dataset,\n",
    "    batch_size  = 16,\n",
    "    num_workers = 4\n",
    ")\n",
    "\n",
    "valid_set_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_set_dataset,\n",
    "    batch_size  = 16,\n",
    "    num_workers = 4\n",
    ")\n",
    "\n",
    "# Get one batch as example.\n",
    "train_data = next(iter(train_set_dataloader))\n",
    "valid_data = next(iter(valid_set_dataloader))\n",
    "\n",
    "# Print the output sizes.\n",
    "print( train_data[\"input_ids\"].size(), valid_data[\"input_ids\"].size() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.bert.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the above code, you are going through all the parameters and set its requires_grad attribute to zero. It means Huggingface will not try to optimize these weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir                  = \"./sentiment-analysis\",\n",
    "    num_train_epochs            = 1,\n",
    "    per_device_train_batch_size = 32,\n",
    "    per_device_eval_batch_size  = 32,\n",
    "    warmup_steps                = 500,\n",
    "    weight_decay                = 0.01,\n",
    "#    save_strategy               = \"epoch\",\n",
    "    evaluation_strategy         = \"steps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Huggingface Trainer object\n",
    "trainer = Trainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_set_dataset,\n",
    "    eval_dataset    = valid_set_dataset,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='938' max='938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [938/938 31:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.682600</td>\n",
       "      <td>0.640213</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>0.660561</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.595393</td>\n",
       "      <td>201.246300</td>\n",
       "      <td>74.536000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=938, training_loss=0.6562134634965519, metrics={'train_runtime': 1863.4143, 'train_samples_per_second': 0.503, 'total_flos': 23526734256000000, 'epoch': 1.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a Checkpoint and get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 03:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.39245537,  0.06493665],\n",
       "       [ 0.23860359,  0.18273208],\n",
       "       [-0.1708882 ,  0.22821526],\n",
       "       ...,\n",
       "       [ 0.16608961, -0.0852609 ],\n",
       "       [-0.01487223,  0.12979108],\n",
       "       [-0.1741466 ,  0.1819702 ]], dtype=float32), label_ids=array([0, 0, 1, ..., 0, 1, 0]), metrics={'eval_loss': 0.638210117816925, 'eval_accuracy': 0.6956, 'eval_f1': 0.6588973554459883, 'eval_precision': 0.7375815353738083, 'eval_recall': 0.5953827460510328, 'eval_runtime': 192.1198, 'eval_samples_per_second': 78.076})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "model = BertForSequenceClassification.from_pretrained(\"./sentiment-analysis/checkpoint-500\")\n",
    "\n",
    "# Make the test set ready\n",
    "test_set_dataset = TheDataset(\n",
    "    document    = test_set.document.tolist(),\n",
    "    label = test_set.label.tolist(),\n",
    "    tokenizer  = tokenizer,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./sentiment-analysis\",\n",
    "    do_predict = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    compute_metrics =compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.predict(test_set_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trainable Paramethers: 108920066\n"
     ]
    }
   ],
   "source": [
    "def calc_net_weight_count(net):\n",
    "    net.train()\n",
    "    net_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "    weight_count = 0\n",
    "    for param in net_params:\n",
    "        weight_count += np.prod(param.size())\n",
    "    return weight_count\n",
    "\n",
    "print( \"Number of Trainable Paramethers:\", calc_net_weight_count(model) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "model = BertForSequenceClassification.from_pretrained(\"./sentiment-analysis/checkpoint-500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>contents</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.01.31</td>\n",
       "      <td>아, 그리고 대전 오월드 버드월드? 만들어져있다해서 거기도 한번 방문해야겠어여!대전...</td>\n",
       "      <td>\\n\\n대전 오월드 :: 대전 동물원 :: 대전 오월드 입장권 :: 대전 오월드 입...</td>\n",
       "      <td>김씨부부네 깨소금네 나는 블로그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.03.11</td>\n",
       "      <td>대전여행중 아이와 갈만한곳 오월드 대전을 가긴갔다! 근데.. 아는곳이 없으니.. 신...</td>\n",
       "      <td>\\n\\n 대전여행중 아이와 갈만한곳 오월드    대전을 가긴갔다!근데.. 아는곳이 ...</td>\n",
       "      <td>메리킴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.04.23</td>\n",
       "      <td>[대전여행] 대전 오월드 플라워랜드튤립축제 저는 어릴 적 튤립을 처음보고 “세상에 ...</td>\n",
       "      <td>\\n\\n \\n\\n[대전여행] 대전 오월드 플라워랜드튤립축제저는 어릴 적 튤립을 처음...</td>\n",
       "      <td>행복을 디자인하는 집</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.07.15</td>\n",
       "      <td>오 오 (무서울때 하는표현) 하더라고요~^^ ［대전 동물원/대전 오월드/대전동물원 ...</td>\n",
       "      <td>\\n\\n \\n \\n［대전동물원/대전 오월드/대전동물원주변맛집］주말당일여행\\n \\n지...</td>\n",
       "      <td>램프의 지니</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.10.23</td>\n",
       "      <td>대전 1박2일 대중교통 이용해서 여행 기차 여행 가보세용 당일치기로도 좋을 듯. 1...</td>\n",
       "      <td>\\n\\n대전 1박2일 대중교통 이용해서 여행기차 여행 가보세용당일치기로도 좋을 듯....</td>\n",
       "      <td>zoomin factory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>14.02.14</td>\n",
       "      <td>대전여행에서 첫번째 들렀던 곳, 대전 오월드 포스팅 먼저 해볼게요! 타지역 여행가면...</td>\n",
       "      <td>\\n\\n\\n\\n\\n대전여행에서 첫번째 들렀던 곳, 대전 오월드 포스팅 먼저 해볼게요...</td>\n",
       "      <td>♥지야월드♥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>13.10.15</td>\n",
       "      <td>대전 오월드, 2013 개인적으로 활동하고 있는 사진 동호회에서 대전 오월드로 출사...</td>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>도미노의 지극히 개인적인 생각</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>14.08.08</td>\n",
       "      <td>즐기다가 온 것 같아요. 대전으로 여행간이유는,- 대학교 1학년때부터 친한 친구가 ...</td>\n",
       "      <td>\\n\\n\\n \\n \\n \\n \\n안뇽하세요 :) 소봉입니다.\\n얼마전에 친구들이랑 ...</td>\n",
       "      <td>소봉이의 데일리 달링♥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>14.10.01</td>\n",
       "      <td>축하해주러 대전으로 고고~ 열심히 박수치며 축하해주고, 끝나고 친구 가족들과 오월드...</td>\n",
       "      <td>\\n\\n2014.09.20.여보의 친구의 아기의 돌잔치를 축하해주러 대전으로 고고~...</td>\n",
       "      <td>결국엔 해피엔딩♡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>15.10.19</td>\n",
       "      <td>&amp;lt; 가을 나들이 - '국화 축제' 대전 오월드 플라워랜드 &amp;gt; IN '소화...</td>\n",
       "      <td>\\n\\n&lt; 가을 나들이 - '국화 축제' 대전 오월드 플라워랜드 &gt;\\n \\n \\nI...</td>\n",
       "      <td>소화테레사의 봄</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2222 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                        description  \\\n",
       "0     20.01.31  아, 그리고 대전 오월드 버드월드? 만들어져있다해서 거기도 한번 방문해야겠어여!대전...   \n",
       "1     15.03.11  대전여행중 아이와 갈만한곳 오월드 대전을 가긴갔다! 근데.. 아는곳이 없으니.. 신...   \n",
       "2     14.04.23  [대전여행] 대전 오월드 플라워랜드튤립축제 저는 어릴 적 튤립을 처음보고 “세상에 ...   \n",
       "3     12.07.15  오 오 (무서울때 하는표현) 하더라고요~^^ ［대전 동물원/대전 오월드/대전동물원 ...   \n",
       "4     16.10.23  대전 1박2일 대중교통 이용해서 여행 기차 여행 가보세용 당일치기로도 좋을 듯. 1...   \n",
       "...        ...                                                ...   \n",
       "2217  14.02.14  대전여행에서 첫번째 들렀던 곳, 대전 오월드 포스팅 먼저 해볼게요! 타지역 여행가면...   \n",
       "2218  13.10.15  대전 오월드, 2013 개인적으로 활동하고 있는 사진 동호회에서 대전 오월드로 출사...   \n",
       "2219  14.08.08  즐기다가 온 것 같아요. 대전으로 여행간이유는,- 대학교 1학년때부터 친한 친구가 ...   \n",
       "2220  14.10.01  축하해주러 대전으로 고고~ 열심히 박수치며 축하해주고, 끝나고 친구 가족들과 오월드...   \n",
       "2221  15.10.19  &lt; 가을 나들이 - '국화 축제' 대전 오월드 플라워랜드 &gt; IN '소화...   \n",
       "\n",
       "                                               contents               name  \n",
       "0     \\n\\n대전 오월드 :: 대전 동물원 :: 대전 오월드 입장권 :: 대전 오월드 입...  김씨부부네 깨소금네 나는 블로그  \n",
       "1     \\n\\n 대전여행중 아이와 갈만한곳 오월드    대전을 가긴갔다!근데.. 아는곳이 ...                메리킴  \n",
       "2     \\n\\n \\n\\n[대전여행] 대전 오월드 플라워랜드튤립축제저는 어릴 적 튤립을 처음...        행복을 디자인하는 집  \n",
       "3     \\n\\n \\n \\n［대전동물원/대전 오월드/대전동물원주변맛집］주말당일여행\\n \\n지...             램프의 지니  \n",
       "4     \\n\\n대전 1박2일 대중교통 이용해서 여행기차 여행 가보세용당일치기로도 좋을 듯....     zoomin factory  \n",
       "...                                                 ...                ...  \n",
       "2217  \\n\\n\\n\\n\\n대전여행에서 첫번째 들렀던 곳, 대전 오월드 포스팅 먼저 해볼게요...             ♥지야월드♥  \n",
       "2218  \\n\\n                                          ...   도미노의 지극히 개인적인 생각  \n",
       "2219  \\n\\n\\n \\n \\n \\n \\n안뇽하세요 :) 소봉입니다.\\n얼마전에 친구들이랑 ...       소봉이의 데일리 달링♥  \n",
       "2220  \\n\\n2014.09.20.여보의 친구의 아기의 돌잔치를 축하해주러 대전으로 고고~...          결국엔 해피엔딩♡  \n",
       "2221  \\n\\n< 가을 나들이 - '국화 축제' 대전 오월드 플라워랜드 >\\n \\n \\nI...           소화테레사의 봄  \n",
       "\n",
       "[2222 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA LOAD\n",
    "column_name = ['date', 'description', 'contents', 'name']\n",
    "df = pd.read_csv('/home/aiffel-dj57/project/오월드 여행 대전.csv')\n",
    "df = df.values.tolist()\n",
    "dataset = pd.DataFrame(df, columns=column_name)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset[0:1700]\n",
    "valid_set = dataset[1700:1961]\n",
    "test_set  = dataset[1961:2222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700\n",
      "261\n",
      "261\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(valid_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       \\n\\n대전 오월드 :: 대전 동물원 :: 대전 오월드 입장권 :: 대전 오월드 입...\n",
       "1       \\n\\n 대전여행중 아이와 갈만한곳 오월드    대전을 가긴갔다!근데.. 아는곳이 ...\n",
       "2       \\n\\n \\n\\n[대전여행] 대전 오월드 플라워랜드튤립축제저는 어릴 적 튤립을 처음...\n",
       "3       \\n\\n \\n \\n［대전동물원/대전 오월드/대전동물원주변맛집］주말당일여행\\n \\n지...\n",
       "4       \\n\\n대전 1박2일 대중교통 이용해서 여행기차 여행 가보세용당일치기로도 좋을 듯....\n",
       "                              ...                        \n",
       "2217    \\n\\n\\n\\n\\n대전여행에서 첫번째 들렀던 곳, 대전 오월드 포스팅 먼저 해볼게요...\n",
       "2218    \\n\\n                                          ...\n",
       "2219    \\n\\n\\n \\n \\n \\n \\n안뇽하세요 :) 소봉입니다.\\n얼마전에 친구들이랑 ...\n",
       "2220    \\n\\n2014.09.20.여보의 친구의 아기의 돌잔치를 축하해주러 대전으로 고고~...\n",
       "2221    \\n\\n< 가을 나들이 - '국화 축제' 대전 오월드 플라워랜드 >\\n \\n \\nI...\n",
       "Name: contents, Length: 2222, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = dataset['contents']\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_data(sentences):\n",
    "\n",
    "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # 입력 토큰의 최대 시퀀스 길이\n",
    "    MAX_LEN = 64\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    \n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 테스트\n",
    "def test_sentences(sentences):\n",
    " \n",
    "    # 평가모드로 변경!!!!!\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22496635 -0.09296724]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['아이가 정말 곰이 됐다.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Iterator' from 'torchtext.data' (/home/aiffel-dj57/anaconda3/envs/aiffel/lib/python3.7/site-packages/torchtext/data/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-bcd87e82d497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Iterator' from 'torchtext.data' (/home/aiffel-dj57/anaconda3/envs/aiffel/lib/python3.7/site-packages/torchtext/data/__init__.py)"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Iterator\n",
    "batch_size = 32\n",
    "train_loader = Iterator(sentences, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'BucketIterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-6cd556e4a2e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m val_iter= sentences.BucketIterator.splits(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         repeat=False)\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'BucketIterator'"
     ]
    }
   ],
   "source": [
    "val_iter= sentences.BucketIterator.splits(\n",
    "        (sentences), batch_size=BATCH_SIZE,\n",
    "        repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
