{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda7af48",
   "metadata": {},
   "source": [
    "# Predict google map review dataset \n",
    "## model\n",
    "- kcbert\n",
    "- fine-tuned with naver shopping review dataset (200,000개)\n",
    "- train 5 epochs\n",
    "- 0.97 accuracy\n",
    "\n",
    "## dataset\n",
    "- google map review of tourist places in Daejeon, Korea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75b940a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, DistributedSampler, random_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from pytorch_lightning.core.lightning import LightningModule \n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.metrics.functional import accuracy, precision, recall\n",
    "from transformers import AdamW, BertForSequenceClassification, AdamW, BertConfig, AutoTokenizer, BertTokenizer, TrainingArguments\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9cdd7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c842c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pj_path = os.getenv('HOME') + '/Projects/JeongCheck'\n",
    "data_path = pj_path + '/compare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae405402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['google_reviews_labeled_spacing_8421.csv',\n",
       " 'google_reviews_labeled_spellcheck_8420.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = os.listdir(data_path)\n",
    "print(len(data_list))\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a5e5b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google_reviews_labeled_spacing_8421.csv',\n",
       " 'google_reviews_labeled_spellcheck_8420.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = os.listdir(data_path)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d7da085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spacing = pd.read_csv(data_path + f'/{file_list[0]}')\n",
    "spell = pd.read_csv(data_path + f'/{file_list[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f05427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>search</th>\n",
       "      <th>keyword</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CoffeeSquare커피광장</td>\n",
       "      <td>4</td>\n",
       "      <td>2일 전</td>\n",
       "      <td>대전시민을 위한 최대 규모의 공연 시설물</td>\n",
       "      <td>대전예술의전당</td>\n",
       "      <td>art_culture_complex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So Young Lee</td>\n",
       "      <td>5</td>\n",
       "      <td>4일 전</td>\n",
       "      <td>코로나 때문에 너무 오랜만에 가본 예술의 전당이였고 공연도 너무 좋았습니다 직원 분...</td>\n",
       "      <td>대전예술의전당</td>\n",
       "      <td>art_culture_complex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>김성수</td>\n",
       "      <td>4</td>\n",
       "      <td>1주 전</td>\n",
       "      <td>시설이 깨끗하고 음향이 좋은 곳입니다</td>\n",
       "      <td>대전예술의전당</td>\n",
       "      <td>art_culture_complex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S.K LEE</td>\n",
       "      <td>5</td>\n",
       "      <td>2주 전</td>\n",
       "      <td>굿 클래식 코로나인데도 연주자들 안전하게 무대에 올려 주셔서 기획자님께 고맙다고 얘...</td>\n",
       "      <td>대전예술의전당</td>\n",
       "      <td>art_culture_complex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지성구</td>\n",
       "      <td>4</td>\n",
       "      <td>2주 전</td>\n",
       "      <td>굿</td>\n",
       "      <td>대전예술의전당</td>\n",
       "      <td>art_culture_complex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  ratings  date  \\\n",
       "0  CoffeeSquare커피광장        4  2일 전   \n",
       "1      So Young Lee        5  4일 전   \n",
       "2               김성수        4  1주 전   \n",
       "3           S.K LEE        5  2주 전   \n",
       "4               지성구        4  2주 전   \n",
       "\n",
       "                                             comment   search  \\\n",
       "0                             대전시민을 위한 최대 규모의 공연 시설물  대전예술의전당   \n",
       "1  코로나 때문에 너무 오랜만에 가본 예술의 전당이였고 공연도 너무 좋았습니다 직원 분...  대전예술의전당   \n",
       "2                               시설이 깨끗하고 음향이 좋은 곳입니다  대전예술의전당   \n",
       "3  굿 클래식 코로나인데도 연주자들 안전하게 무대에 올려 주셔서 기획자님께 고맙다고 얘...  대전예술의전당   \n",
       "4                                                  굿  대전예술의전당   \n",
       "\n",
       "               keyword  label  \n",
       "0  art_culture_complex      1  \n",
       "1  art_culture_complex      1  \n",
       "2  art_culture_complex      1  \n",
       "3  art_culture_complex      1  \n",
       "4  art_culture_complex      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f37bdd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>search</th>\n",
       "      <th>keyword</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박성균</td>\n",
       "      <td>3</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>맥주축제</td>\n",
       "      <td>세계엑스포기념품박물관</td>\n",
       "      <td>expo_science_park</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Алексе́й</td>\n",
       "      <td>5</td>\n",
       "      <td>2년 전</td>\n",
       "      <td>역대 엑스포 개최 도시의 기념품과 희귀한 아이템을 한곳에서 볼 수 있습니다</td>\n",
       "      <td>세계엑스포기념품박물관</td>\n",
       "      <td>expo_science_park</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robert Helvie</td>\n",
       "      <td>3</td>\n",
       "      <td>4년 전</td>\n",
       "      <td>남북한에 관한 흥미로운 것들 거기에서 많은 시간을 보내지 않아도 됩니다 옆집 과학 ...</td>\n",
       "      <td>세계엑스포기념품박물관</td>\n",
       "      <td>expo_science_park</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hyung-jun kjun</td>\n",
       "      <td>1</td>\n",
       "      <td>5년 전</td>\n",
       "      <td>엑스포는 없고 너무 지루했어</td>\n",
       "      <td>세계엑스포기념품박물관</td>\n",
       "      <td>expo_science_park</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Onur Ozsoy</td>\n",
       "      <td>5</td>\n",
       "      <td>1년 전</td>\n",
       "      <td>주말에는 대개 혼잡합니다 야외 콘서트 및 엔터테인먼트 길거리 음식 작은 기념품은 지...</td>\n",
       "      <td>엑스포음악분수</td>\n",
       "      <td>expo_science_park</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  ratings  date  \\\n",
       "0             박성균        3  1년 전   \n",
       "1        Алексе́й        5  2년 전   \n",
       "2   Robert Helvie        3  4년 전   \n",
       "3  hyung-jun kjun        1  5년 전   \n",
       "4      Onur Ozsoy        5  1년 전   \n",
       "\n",
       "                                             comment       search  \\\n",
       "0                                               맥주축제  세계엑스포기념품박물관   \n",
       "1          역대 엑스포 개최 도시의 기념품과 희귀한 아이템을 한곳에서 볼 수 있습니다  세계엑스포기념품박물관   \n",
       "2  남북한에 관한 흥미로운 것들 거기에서 많은 시간을 보내지 않아도 됩니다 옆집 과학 ...  세계엑스포기념품박물관   \n",
       "3                                    엑스포는 없고 너무 지루했어  세계엑스포기념품박물관   \n",
       "4  주말에는 대개 혼잡합니다 야외 콘서트 및 엔터테인먼트 길거리 음식 작은 기념품은 지...      엑스포음악분수   \n",
       "\n",
       "             keyword  label  \n",
       "0  expo_science_park      0  \n",
       "1  expo_science_park      1  \n",
       "2  expo_science_park      1  \n",
       "3  expo_science_park      0  \n",
       "4  expo_science_park      1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bfa6284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8421, 8420)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacing), len(spell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "872c3b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name       0\n",
      "ratings    0\n",
      "date       0\n",
      "comment    0\n",
      "search     0\n",
      "keyword    0\n",
      "label      0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "name       0\n",
      "ratings    0\n",
      "date       0\n",
      "comment    0\n",
      "search     0\n",
      "keyword    0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(spacing.isna().sum())\n",
    "print('\\n')\n",
    "print(spell.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b2493e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n",
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "print(set(spacing.label))\n",
    "print(set(spell.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2300948e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(spacing[spacing.label==2]))\n",
    "print(len(spell[spell.label==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36296113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8421 8420\n"
     ]
    }
   ],
   "source": [
    "test_spac = spacing.copy()\n",
    "test_spel = spell.copy()\n",
    "\n",
    "print(len(test_spac), len(test_spel))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190f574",
   "metadata": {},
   "source": [
    "중립 데이터 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "073c6ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8389\n"
     ]
    }
   ],
   "source": [
    "test_spac = test_spac[test_spac.label != 2]\n",
    "print(len(test_spac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62380e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8386\n"
     ]
    }
   ],
   "source": [
    "test_spel = test_spel[test_spel.label != 2]\n",
    "print(len(test_spel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5838f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "202cbd19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    pj_path + \"/bert_model/checkpoint-2000\",\n",
    "    num_labels = 2, \n",
    "                    \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "062cbe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30000, 768)\n",
      "bert.embeddings.position_embeddings.weight                (300, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ed74a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_data(sentences):\n",
    "\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "    MAX_LEN = 64\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    \n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "        \n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23010aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentences(sentences):\n",
    " \n",
    "    # 평가모드로 변경!!!!!\n",
    "    model.eval()\n",
    "\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f08572e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6033c76a",
   "metadata": {},
   "source": [
    "## 데이터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3cc6695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "\n",
    "    df.document=df.comment.replace('[^A-Za-zㄱ-ㅎㅏ-ㅣ가-힣]+','')\n",
    "\n",
    "    return df\n",
    "\n",
    "# result = preprocessing(gr_data)\n",
    "# result = result.dropna()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a66036b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성분석할 comment 추출 \n",
    "def export_com(preprocessed_df):\n",
    "    sens =[]\n",
    "    for sen in preprocessed_df.comment:\n",
    "        sens.append(sen)\n",
    "    print('check lenght :', len(sens), len(preprocessed_df)) # 개수 확인 \n",
    "    print('sample sentence :', sens[1])\n",
    "    return sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf57cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predicted_label(sen):\n",
    "    sen = [sen]\n",
    "    score = test_sentences(sen)\n",
    "    result = np.argmax(score)\n",
    "\n",
    "    if result == 0:   # negative \n",
    "        return 0\n",
    "    elif result == 1: # positive\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d59664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model, df, place_name):\n",
    "    result = preprocessing(df)\n",
    "    result = result.dropna()\n",
    "    \n",
    "    sens = export_com(result)\n",
    "    \n",
    "    scores_data=[]\n",
    "    for sen in sens:\n",
    "        scores_data.append(make_predicted_label(sen))\n",
    "        \n",
    "    df['pred'] = scores_data    \n",
    "    \n",
    "    cor = df[df.label == df.pred]\n",
    "    uncor = df[df.label != df.pred]\n",
    "    \n",
    "    print('correct prediction num :', len(cor))\n",
    "    print('uncorrect prediction num :', len(uncor))\n",
    "    print('correct label check :' ,set(cor.label))\n",
    "    \n",
    "#     df.to_csv(pj_path + f'/sentiment_data/{place_name}_pred_kcbert.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dcb8e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### spacing ###\n",
      "check lenght : 8389 8389\n",
      "sample sentence : 코로나 때문에 너무 오랜만에 가본 예술의 전당이였고 공연도 너무 좋았습니다 직원 분들도 너무 친절했구요 있는 공연들 최대한 아이들과 많이 가보려구요 가시는 분들 모두 좋은 시간 보내세요\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj26/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct prediction num : 6708\n",
      "uncorrect prediction num : 1681\n",
      "correct label check : {0, 1}\n",
      "### spell ###\n",
      "check lenght : 8386 8386\n",
      "sample sentence : 역대 엑스포 개최 도시의 기념품과 희귀한 아이템을 한곳에서 볼 수 있습니다\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel-dj26/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct prediction num : 6715\n",
      "uncorrect prediction num : 1671\n",
      "correct label check : {0, 1}\n"
     ]
    }
   ],
   "source": [
    "print('### spacing ###')\n",
    "predict_spac = predict_label(model, test_spac, 'total')\n",
    "print('### spell ###')\n",
    "predict_spel = predict_label(model, test_spel, 'total')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0acd20",
   "metadata": {},
   "source": [
    "## Loss (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b683be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "899cfdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import math\n",
    "    print('lenght check (origin, prediction):', len(y), len(y_pred))\n",
    "\n",
    "    rmse_label = math.sqrt(mean_squared_error(y, y_pred))\n",
    "    print('rmse of label :', rmse_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df42fa",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "586fb8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y, y_pred, total):\n",
    "    correct = (y_pred == y).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the {total} test text: %d %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14511a5",
   "metadata": {},
   "source": [
    "## f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8f79c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "154fc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y, y_pred):\n",
    "    score = f1_score(y, y_pred)\n",
    "    report = classification_report(y, y_pred)\n",
    "    \n",
    "    print('f1 score :', score)\n",
    "    print('===== classification report =====')\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ab7707",
   "metadata": {},
   "source": [
    "## calculate performance\n",
    "- RMSE\n",
    "- Accuracy\n",
    "- f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f1401fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_perform(df):\n",
    "    y = df.label\n",
    "    y_pred = df.pred\n",
    "    if len(y) == len(y_pred):\n",
    "        total = len(y)\n",
    "        print('label length :', total)\n",
    "    else:\n",
    "        print('It has different length !')\n",
    "    \n",
    "    rmse(y, y_pred)\n",
    "    acc(y, y_pred, total)\n",
    "    f1(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e22fd9e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== spacing =====\n",
      "label length : 8389\n",
      "lenght check (origin, prediction): 8389 8389\n",
      "rmse of label : 0.44763986853418153\n",
      "Accuracy of the network on the 8389 test text: 79 %\n",
      "f1 score : 0.872699734948883\n",
      "===== classification report =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.74      0.53      1274\n",
      "           1       0.95      0.81      0.87      7115\n",
      "\n",
      "    accuracy                           0.80      8389\n",
      "   macro avg       0.68      0.78      0.70      8389\n",
      "weighted avg       0.86      0.80      0.82      8389\n",
      "\n",
      "===== spell =====\n",
      "label length : 8386\n",
      "lenght check (origin, prediction): 8386 8386\n",
      "rmse of label : 0.44638623696243956\n",
      "Accuracy of the network on the 8386 test text: 80 %\n",
      "f1 score : 0.8733035105011752\n",
      "===== classification report =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.75      0.53      1276\n",
      "           1       0.95      0.81      0.87      7110\n",
      "\n",
      "    accuracy                           0.80      8386\n",
      "   macro avg       0.68      0.78      0.70      8386\n",
      "weighted avg       0.87      0.80      0.82      8386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('===== spacing =====')\n",
    "cal_perform(predict_spac)\n",
    "print('===== spell =====')\n",
    "cal_perform(predict_spel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
